# -*- coding: utf-8 -*-
"""Hands-On: 5 Data Cleaning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j83OmTZgiF0dWb_iXXHtrv-Cx-wYezOL
"""

#Import the required packages and read data from patient.csv in a dataframe
import numpy as np
import pandas as pd

data=pd.read_csv('patient.csv')
data.head()

#Take a look at the percentage of null values in each column.

data.isnull().sum()/data.shape[0]

#Replace every occurrence of 0, empty string and NULL with np.nan.

data.replace(to_replace=['0',' ','NULL'],value=np.nan,inplace=True)

#Extract all numeric data and check amount of null values.

numeric_data=data.select_dtypes(exclude=['object'])

numeric_data.isnull().sum()

#Drop every row with null values and check the shape of data after that.

not_na_data=numeric_data.dropna()

not_na_data.shape

#Drop every column with null values and check the shape of data after that

numeric_data.dropna(axis=1).head()

#Fill every null value with 0 and take a look at the head of data.

numeric_data.fillna(0).head()

#Fill every null value with mean of that column and take a look at the number of null values after that.

mean_filled=numeric_data.fillna(numeric_data.mean())

mean_filled.isnull().sum()

